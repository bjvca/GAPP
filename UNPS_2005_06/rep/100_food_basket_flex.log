----------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /home/bjvca/data/data/GAP/Haruna/UNPS_2005_06//rep/100_food_basket_flex.log
  log type:  text
 opened on:  10 Mar 2014, 14:47:25

. clear

. set more off

. #delimit ;
delimiter now ;
. **************************************************************************
> * 100_food_basket_flex.do     (start)
> *
> * This file is to get the data from the cons_cod.dta in work and then 
> * to create the do file with the 90% of the consumption expenditures 
> * using a flexible basket of goods.
> *
> * NOTE: we actually keep goods representing 95% of expenditure
> * in order to facilitate dropping of some goods (such as rats) where
> * quantity and nutrition information is unknown.
> *
> * We base our basket on the bottom 60 percent of consumption per capita
> * (weighted by hhweight*hhsize). We use the TEMPORALLY-ADJUSTED
> * NOMINAL consumption because we don't have a spatial adjustment yet.
> *
> * (Then we iterate this process to arrive at a final food bundle in later code)
> **************************************************************************;
. *CA modified to bring in hhdata into bootstrap;
. /*
> This file uses:
>                 work/cons_cod.dta
>                 work/hhdata.dta
>                 work/products.dta
>                 work/consump_nom.dta
>                 work/temp_index_reg_tpi.dta
>                 work/food_cat.dta
> 
> This file creates:
>                 work/food_basket_flex.dta
>                 work/codes_food_basket_flex.dta
> */
> 
> 
> 
> *do "$path/new/010_initial.do";
. **************************************************************************;
. * First, make a small temp file that has the temporally adjusted 
> * nominal consumption per capita, using work/consump_nom and 
> * work/temp_index_reg_tpi.dta. Make a dummy variable indicating
> * whether they are in the bottom 60%.
> **************************************************************************;
. use "$path/work/conpc.dta", clear;

. *use "$path/work/consump_nom.dta", clear;
. *CA modified to merge in work/hhdata.dta for bootstrap;
.         sort hhid;

.         merge hhid using "$path/work/hhdata.dta";

.         tab _m;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |          1        0.03        0.03
          3 |      3,123       99.97      100.00
------------+-----------------------------------
      Total |      3,124      100.00

.         drop _m;

.         keep hhid hhweight hhsize cons_pc_nom reg_tpi rural survquar;

.         sort reg_tpi survquar;

.         cap drop _merge;

.         merge reg_tpi survquar using "$path/work/temp_index_reg_tpi.dta";
variables reg_tpi survquar do not uniquely identify observations in the master data
(label lsurvquar already defined)
(label lregion already defined)

.         tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |         15        0.48        0.48
          3 |      3,109       99.52      100.00
------------+-----------------------------------
      Total |      3,124      100.00

.         drop _merge;

.         sort hhid;

.         merge hhid using "$path/work/conpc.dta";

.         tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          3 |      3,124      100.00      100.00
------------+-----------------------------------
      Total |      3,124      100.00

.         drop _merge;

.                 gen food_pc_tpi  = food_pc_nom /tpi_trim;
(15 missing values generated)

.         lab var food_pc_tpi "Temp-adjusted per capita food consumption/day";

.         gen cons_pc_tpi = food_pc_tpi + nf_pc_nom;
(16 missing values generated)

.         lab var cons_pc_tpi "Temp adjusted total consumption/day";

.         gen one=1;

.         tempfile contpi;

.         save `contpi', replace;
(note: file /tmp/St02564.000001 not found)
file /tmp/St02564.000001 saved

.         collapse (p$bottom) one cons_pc_tpi [aw=hhsize*hhweight] ;

.         rename cons_pc_tpi pctile_60;

.         tempfile 60pct;

.         sort one;

.         save `60pct', replace;
(note: file /tmp/St02564.000002 not found)
file /tmp/St02564.000002 saved

.                 use `contpi';

.                 sort one;

.                 merge one using `60pct';
variable one does not uniquely identify observations in the master data

.                 tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          3 |      3,124      100.00      100.00
------------+-----------------------------------
      Total |      3,124      100.00

.                 drop _merge;

.                 drop one;

.                         gen bottom_basket=cons_pc_tpi< pctile_60;

.                 tab bottom_basket [aw=hhsize*hhweight];

bottom_bask |
         et |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 | 1,564.9929       50.18       50.18
          1 | 1,554.0071       49.82      100.00
------------+-----------------------------------
      Total |      3,119      100.00

.                 lab var bottom_basket "=1 if in bottom 60% of PCE";

.                                 sort hhid;

. save `contpi' , replace;
file /tmp/St02564.000001 saved

. **************************************************************************;
. * Next, need to keep only the food products in order to calculate the 
> * food poverty line, and then calculate the food expenses by code.
> **************************************************************************;
. use "$path/work/cons_cod.dta";

. /*
>         sort product;
>         merge product using "$path/work/food_cat.dta";
>         tab _merge;
>         keep if _merge==3;
>         drop _merge;
> */
>         
>         keep if food_cat==1;
(3977 observations deleted)

.         codebook hhid;

----------------------------------------------------------------------------------------------
hhid                                                   Unique HH Identifier Across Panel Waves
----------------------------------------------------------------------------------------------

                  type:  numeric (double)

                 range:  [1.013e+09,4.193e+09]        units:  1
         unique values:  3120                     missing .:  0/38998

                  mean:   2.3e+09
              std. dev:   1.2e+09

           percentiles:        10%       25%       50%       75%       90%
                           1.0e+09   1.1e+09   2.1e+09   3.2e+09   4.1e+09

.         sort hhid;

. **************************************************************************;
. * Next, merge in the consumption information, and select those in bottom
> * 60% of nominal distribution, after making temporal adjustment. 
> **************************************************************************;
.         merge hhid using `contpi';
variable hhid does not uniquely identify observations in the master data

.         tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          2 |          4        0.01        0.01
          3 |     38,998       99.99      100.00
------------+-----------------------------------
      Total |     39,002      100.00

.         keep if _merge==3;
(4 observations deleted)

.         drop _merge;

.         keep if bottom_basket==1;
(25093 observations deleted)

.      **************************************************************************;
. * Calculate food shares. Since we're only doing shares here, we can
> * work with the expenditures without doing temporal adjustment.
> **************************************************************************;
.           gen  food_expenditure= cod_hh_nom;

.                             *gen  food_expenditure= own_valued + daily_valued + monthly_valu
> ed + educ_valued;
.           egen tot_food_expen= sum (food_expen), by (hhid) ;

.           count if food_expenditure==.;
    0

.           count if tot_food_expen==.;
    0

.                     gen food_share= food_expenditure/tot_food_expen;

.           count if food_share==.;
    0

.           drop if food_share==.;
(0 observations deleted)

.           sort hhid product;

.                         tempfile food_basket_flex;

. save `food_basket_flex', replace;
(note: file /tmp/St02564.000003 not found)
file /tmp/St02564.000003 saved

. ********************************************************************************;
. * Now prepare to get the variable spdomain to the using dataset, and then find the 
> * total shares by each product in order to select the most important goods in the 
> * basket.
> ********************************************************************************;
.                 preserve;

.                 use "$path/work/hhdata.dta", clear;

.                         keep hhid spdomain;

.                         sort hhid;

.                         tempfile spdomain;

.                 save `spdomain' , replace;
(note: file /tmp/St02564.000005 not found)
file /tmp/St02564.000005 saved

.                 restore;

.                            collapse (mean) hhweight, by (hhid);

.            sort hhid ;

.             merge hhid using `spdomain';

.            tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          2 |      1,766       56.55       56.55
          3 |      1,357       43.45      100.00
------------+-----------------------------------
      Total |      3,123      100.00

.            drop if _m==2;
(1766 observations deleted)

.            drop _merge;

.             collapse (sum) hhweight , by(spdomain);

.            rename hhweight tothhweight;

.            tempfile tothhweight;

. save `tothhweight';
file /tmp/St02564.000006 saved

. use `food_basket_flex';

.           sort hhid;

.           merge hhid using `spdomain';
variable hhid does not uniquely identify observations in the master data

.           tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          2 |      1,766       11.27       11.27
          3 |     13,905       88.73      100.00
------------+-----------------------------------
      Total |     15,671      100.00

.           sort _m;

.           drop if _m==2;
(1766 observations deleted)

.           drop _m;

.           sort spdomain;

.             merge spdomain using `tothhweight';
variable spdomain does not uniquely identify observations in the master data
(label lspdomain already defined)

.           tab _merge;

     _merge |      Freq.     Percent        Cum.
------------+-----------------------------------
          3 |     13,905      100.00      100.00
------------+-----------------------------------
      Total |     13,905      100.00

.           drop _merge;

.             sort spdomain product;

.             gen f_share_w=(food_share*hhweight)/tothhweight;

.                                                 *drop descript;
.                         *gen descript = 0;
.             collapse (sum) f_share_w, by(spdomain product);

.                      sort spdomain f_share_w;

.           by spdomain: gen cumshr= sum(f_share_w);

.                     count if cumshr<=.075;
  118

.           drop if cumshr<=.075;
(118 observations deleted)

.             lab var f_share_w "average food share for the 13 regions";

. save "$path/work/food_basket_flex.dta", replace;
file /home/bjvca/data/data/GAP/Haruna/UNPS_2005_06//work/food_basket_flex.dta saved

. * List first spatial region to get an idea about contents;
. list product spdomain f_share_w cumshr if spdomain==1;

     +-----------------------------------------------+
     | product        spdomain   f_shar~w     cumshr |
     |-----------------------------------------------|
  1. |     149   Central Urban     .00871   .0760886 |
  2. |     150   Central Urban   .0094023   .0854908 |
  3. |     114   Central Urban   .0099662    .095457 |
  4. |     134   Central Urban   .0119157   .1073727 |
  5. |     125   Central Urban    .012526   .1198987 |
     |-----------------------------------------------|
  6. |     135   Central Urban   .0141241   .1340228 |
  7. |     140   Central Urban    .016719   .1507417 |
  8. |     117   Central Urban   .0194072   .1701489 |
  9. |     161   Central Urban   .0276729   .1978219 |
 10. |     127   Central Urban   .0277953   .2256172 |
     |-----------------------------------------------|
 11. |     136   Central Urban   .0294572   .2550744 |
 12. |     122   Central Urban   .0308958   .2859702 |
 13. |     157   Central Urban   .0362997   .3222699 |
 14. |     123   Central Urban   .0376731    .359943 |
 15. |     144   Central Urban   .0507403   .4106833 |
     |-----------------------------------------------|
 16. |     141   Central Urban    .053628   .4643113 |
 17. |     100   Central Urban   .0608637    .525175 |
 18. |     105   Central Urban   .0690821    .594257 |
 19. |     107   Central Urban   .0830494   .6773064 |
 20. |     147   Central Urban   .0905686   .7678751 |
     |-----------------------------------------------|
 21. |     113   Central Urban   .1092901   .8771651 |
 22. |     110   Central Urban   .1228348          1 |
     +-----------------------------------------------+

.                     gen numreg=1;

.           collapse (sum) numreg cumshr, by (product);

.                           keep product  numreg;

.           display _N;
39

.                     lab var numreg "number of goods in the basket";

. /*
>           merge product using "$path/work/products.dta";
>             tab _merge;
>           keep if _merge==3;
> */
>           keep product  numreg;

.             sort product;

.                display _N;
39

.   save "$path/work/codes_food_basket_flex.dta", replace;
file /home/bjvca/data/data/GAP/Haruna/UNPS_2005_06//work/codes_food_basket_flex.dta saved

. **************************************************************************
> * 100_food_basket_flex.do     (end)
> **************************************************************************;
. cap log close;
